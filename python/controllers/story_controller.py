import os
import openai
import tempfile
from playsound import playsound
import asyncio
from dotenv import load_dotenv
import streamlit as st
from openai import OpenAI
from io import BytesIO
import requests
import cv2
import numpy as np
from PIL import Image
import random
import re
from typing import Optional
import base64

load_dotenv()  # .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ

# OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°
openai_api_key = os.getenv('OPENAI_API_KEY')

# 1. ë³€ìˆ˜ì— ê°’ í• ë‹¹í•˜ê¸°
#openai_api_key = st.secrets["OpenAI"]["OPENAI_API_KEY"]

# 2. ê°’ì´ ì—†ìœ¼ë©´ ì—ëŸ¬ ì²˜ë¦¬
if not openai_api_key:
    raise ValueError("í™˜ê²½ë³€ìˆ˜ 'OPENAI_API_KEY'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# 3. openaiì— API í‚¤ ë“±ë¡
openai.api_key = openai_api_key

client = OpenAI(api_key=openai_api_key)


# You are a fairy tale writer.

# Please write a long and rich fairy tale in Korean about '{thema}', with the main character named '{name}'.  
# The main character can be various animals.  
# Include detailed descriptions of the characters, background, and events,  
# and write in a warm and gentle tone as if a mother is reading the story to her child.

# ë™í™” ìƒì„± í•¨ìˆ˜
def generate_fairy_tale(name, thema):
    prompt = (
        f"""
        ë„ˆëŠ” ë™í™” ì‘ê°€ì•¼.
        '{thema}'ë¥¼ ì£¼ì œë¡œ, '{name}'ì´ ì£¼ì¸ê³µì¸ ê¸¸ê³  ì•„ë¦„ë‹¤ìš´ ë™í™”ë¥¼ ì¨ì¤˜.
        ì—„ë§ˆê°€ ì•„ì´ì—ê²Œ ì½ì–´ì£¼ë“¯ ë‹¤ì •í•œ ë§íˆ¬ë¡œ ì¨ì¤˜.
        """
    )
    try:
        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=16384,
            temperature=0.5
        )
        return completion.choices[0].message.content
    except Exception as e:
        return f"ë™í™” ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"


# # ìŒì„± ì¬ìƒ í•¨ìˆ˜
# def play_openai_voice(text, voice="alloy", speed=1):
#     # 1. TTS ìŒì„± ìƒì„±
#     try:
#         response = openai.audio.speech.create(
#             model="tts-1",
#             voice=voice,
#             input=text,
#             speed=speed # ì†ë„ ì¡°ì ˆ (1.0ì´ ê¸°ë³¸ ì†ë„, 0.5ëŠ” ëŠë¦¬ê²Œ, 2.0ì€ ë¹ ë¥´ê²Œ)
#         )
#         # # 2. ì„ì‹œ íŒŒì¼ì— ì €ì¥
#         # tmp_path = None
#         # if hasattr(response, 'content') and response.content:
#         #     with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_file:
#         #         tmp_file.write(response.content)
#         #         tmp_path = tmp_file.name
#         # else:
#         #     st.error("TTS ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.")
#         #     return None
#         # return tmp_path

#         # 2. ì˜êµ¬ íŒŒì¼ì— ì €ì¥ (ì„ì‹œ íŒŒì¼ ëŒ€ì‹ )
#         audio_filename = f"tts_audio_{voice}_{hash(text) % 10000}.mp3"
#         audio_path = os.path.join(".", audio_filename)
        
#         # ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ì‚­ì œ
#         if os.path.exists(audio_path):
#             os.remove(audio_path)
        
#         # ìƒˆ íŒŒì¼ë¡œ ì €ì¥
#         with open(audio_path, "wb") as audio_file:
#             audio_file.write(response.content)
        
#         print(f"ìŒì„± íŒŒì¼ ìƒì„± ì™„ë£Œ: {audio_path} (voice: {voice})")
#         return audio_path
        
#     except Exception as e:
#         print(f"TTS ìƒì„± ì˜¤ë¥˜: {e}")
#         return None

# OpenAI TTSë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„± ë°ì´í„° ìƒì„± (íŒŒì¼ ì €ì¥ ì—†ìŒ)
def generate_openai_voice(text, voice="alloy", speed=1.0):
    try:
        # TTS ìŒì„± ìƒì„±
        response = openai.audio.speech.create(
            model="tts-1",
            voice=voice,
            input=text,
            speed=speed
        )
        
        # ë°”ì´ë„ˆë¦¬ ë°ì´í„° ì§ì ‘ ë°˜í™˜
        return response.content
        
    except Exception as e:
        print(f"TTS ìƒì„± ì˜¤ë¥˜: {e}")
        return None

def audio_to_base64(audio_data):
    """
    ì˜¤ë””ì˜¤ ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ Base64ë¡œ ì¸ì½”ë”©
    ëª¨ë°”ì¼ ì•±ì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•¨
    """
    if audio_data:
        return base64.b64encode(audio_data).decode('utf-8')
    return None




# # ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜ (Dall-E 3 ì‚¬ìš©)
# def generate_image_from_fairy_tale(fairy_tale_text):
#     # í”„ë¡¬í”„íŠ¸ ì˜ì–´ë¡œ ìƒì„± ì‹œ ì‘ë‹µ ë‚´ìš© ë” ì •í™•í•´ì§
#     try:
#         base_prompt = fairy_tale_text[:300].replace('\n', ' ')

#         prompt = (
#             "Make sure there is no text in the image "
#             "Minimul detail "
#             f"Please create a single, simple illustration that matches the content about {base_prompt}, in a child-friendly style. "
#         )

#         response = client.images.generate(
#             model="dall-e-3",
#             prompt=prompt,
#             size="1024x1024",
#             quality="standard",
#             n=1
#         )
        
#         if hasattr(response, "data") and response.data and len(response.data) > 0:
#             return response.data[0].url
#         else:
#             print("ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: ì‘ë‹µì´ ë¹„ì–´ ìˆê±°ë‚˜ í˜•ì‹ì´ ì˜ëª»ë¨.")
#             print("ì „ì²´ ì‘ë‹µ:", response)
#             return None
#     except Exception as e:
#         print(f"ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ:\n{e}")
#         return None

# ì¤‘ë³µë˜ì§€ ì•ŠëŠ” íŒŒì¼ëª… ìƒì„± í•¨ìˆ˜
def get_available_filename(base_name: str, extension: str = ".png", folder: str = ".") -> str:
    """
    ì¤‘ë³µë˜ì§€ ì•ŠëŠ” íŒŒì¼ëª…ì„ ìë™ìœ¼ë¡œ ìƒì„±
    ì˜ˆ: fairy_tale_image.png, fairy_tale_image_1.png, ...
    """
    counter = 0
    while True:
        filename = f"{base_name}{f'_{counter}' if counter > 0 else ''}{extension}"
        filepath = os.path.join(folder, filename)
        if not os.path.exists(filepath):
            return filepath
        counter += 1

# í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜ (staility_sdxlëŠ” ì˜ì–´ë§Œ ì²˜ë¦¬ ê°€ëŠ¥)
def generate_image_prompt_from_story(fairy_tale_text: str) -> Optional[str]:
    """
    ë™í™” ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„±ìš© ì˜ì–´ í”„ë¡¬í”„íŠ¸ ìƒì„±
    """
    try:
        system_prompt = (
            "You are a prompt generator for staility_sdxl. "
            f"From the given {fairy_tale_text}, choose one vivid, heartwarming scene. "
            "Describe it in English in a single short sentence suitable for generating a simple, child-friendly fairy tale illustration style. "
            "Use a soft, cute, minimal detail. "
            "No text, no words, no letters, no signs, no numbers."
        )

        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ë‹¤ìŒì€ ë™í™”ì•¼:\n\n{fairy_tale_text}\n\nì´ ë™í™”ì— ì–´ìš¸ë¦¬ëŠ” ê·¸ë¦¼ì„ ê·¸ë¦´ ìˆ˜ ìˆë„ë¡ í”„ë¡¬í”„íŠ¸ë¥¼ ì˜ì–´ë¡œ ì§§ê²Œ ì¨ì¤˜."}
            ],
            temperature=0.5,
            max_tokens=150
        )

        return completion.choices[0].message.content.strip()

    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
        return None


# ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜ (staility_sdxl ì‚¬ìš©)
def generate_image_from_fairy_tale(fairy_tale_text):
    # í”„ë¡¬í”„íŠ¸ ì˜ì–´ë¡œ ìƒì„± ì‹œ ì‘ë‹µ ë‚´ìš© ë” ì •í™•í•´ì§
    try:
        endpoint = "https://api.stability.ai/v2beta/stable-image/generate/core"
        
        
        # ë™í™” í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬
        base_prompt = generate_image_prompt_from_story(fairy_tale_text)
        if not base_prompt:
            st.error("ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return None

        prompt = (
            "no text in the image "
            "Minimul detail "
            f"Please create a single, simple illustration that matches the content about {base_prompt}, in a child-friendly style. "
        )

        headers = {
            "Authorization": f"Bearer {os.getenv('STABILITY_API_KEY')}",
            "Accept": "image/*",
        }

        # multipart/form-data í˜•íƒœë¡œ ë°ì´í„° ì „ì†¡
        files = {
            "prompt": (None, prompt),
            "model": (None, "stable-diffusion-xl-1024-v1-0"),
            "output_format": (None, "png"),
            "height": (None, "1024"),
            "width": (None, "1024"),
            "seed": (None, "1234")
        }

        response = requests.post(endpoint, headers=headers, files=files)

        if response.status_code == 200:
            save_path = get_available_filename("fairy_tale_image", ".png", folder=".")
            with open(save_path, "wb") as f:
                f.write(response.content)
            print(f"ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {save_path}")
            return save_path
        else:
            print("ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨:", response.status_code)
            print("ì‘ë‹µ ë‚´ìš©:", response.text)
            return None

    except Exception as e:
        print(f"ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ:\n{e}")
        return None


# í‘ë°± ì´ë¯¸ì§€ ë³€í™˜ (Dalle-E 3 ì´ë¯¸ì§€ ìš©)
# def convert_bw_image(image_url, save_path="bw_image.png"):
#     try:
#         response = requests.get(image_url)
#         image = Image.open(BytesIO(response.content)).convert("RGB")

#         # Numpy ë°°ì—´ë¡œ ë³€í™˜
#         np_image = np.array(image)

#         # í‘ë°± ë³€í™˜
#         gray = cv2.cvtColor(np_image, cv2.COLOR_RGB2GRAY)

#         # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë…¸ì´ì¦ˆ ì œê±°
#         blurred = cv2.GaussianBlur(gray, (3, 3), 0)

#         # ìºë‹ˆ ì—£ì§€ ë””í…ì…˜ (ë” ë¶€ë“œëŸ¬ìš´ ì„ )
#         edges = cv2.Canny(blurred, 50, 150)
        
#         # ì„  ë‘ê»˜ ì¡°ì ˆ
#         kernel = np.ones((2,2), np.uint8)
#         dilated_edges = cv2.dilate(edges, kernel, iterations=1)
        
#         # í° ë°°ê²½ì— ê²€ì€ ì„ 
#         line_drawing = 255 - dilated_edges
        
#         # ì´ë¯¸ì§€ ì €ì¥
#         cv2.imwrite(save_path, line_drawing)
#         return save_path
    
#     except Exception as e:
#         print(f"ë³€í™˜ ì˜¤ë¥˜: {e}")
#         return None

# í‘ë°± ì´ë¯¸ì§€ ë³€í™˜ (URLê³¼ ë¡œì»¬ íŒŒì¼ ëª¨ë‘ ì§€ì›)
def convert_bw_image(image_input, save_path=None):
    try:
        print(f"ğŸ¨ [convert_bw_image] ë³€í™˜ ì‹œì‘: {image_input}")
        
        # ì €ì¥ ê²½ë¡œê°€ ì§€ì •ë˜ì§€ ì•Šì€ ê²½ìš° ìë™ ìƒì„±
        if save_path is None:
            save_path = get_available_filename("bw_fairy_tale_image", ".png", folder=".")
            print(f"ğŸ” [convert_bw_image] ìë™ ìƒì„±ëœ ì €ì¥ ê²½ë¡œ: {save_path}")

        # URLì¸ì§€ ë¡œì»¬ íŒŒì¼ì¸ì§€ íŒë‹¨
        if image_input.startswith(('http://', 'https://')):
            print(f"ğŸŒ [convert_bw_image] URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...")
            # URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            response = requests.get(image_input, timeout=30)
            if response.status_code != 200:
                raise Exception(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: HTTP {response.status_code}")
            image = Image.open(BytesIO(response.content)).convert("RGB")
            print(f"âœ… [convert_bw_image] URL ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ")
        else:
            print(f"ğŸ“ [convert_bw_image] ë¡œì»¬ íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ ì¤‘...")
            # ë¡œì»¬ íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ
            if not os.path.exists(image_input):
                raise Exception(f"ë¡œì»¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_input}")
            image = Image.open(image_input).convert("RGB")
            print(f"âœ… [convert_bw_image] ë¡œì»¬ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ")

        # Numpy ë°°ì—´ë¡œ ë³€í™˜
        np_image = np.array(image)
        print(f"ğŸ” [convert_bw_image] ì´ë¯¸ì§€ í¬ê¸°: {np_image.shape}")

        # í‘ë°± ë³€í™˜
        gray = cv2.cvtColor(np_image, cv2.COLOR_RGB2GRAY)

        # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë…¸ì´ì¦ˆ ì œê±°
        blurred = cv2.GaussianBlur(gray, (3, 3), 0)

        # ìºë‹ˆ ì—£ì§€ ë””í…ì…˜ (ë” ë¶€ë“œëŸ¬ìš´ ì„ )
        edges = cv2.Canny(blurred, 50, 150)
        
        # ì„  ë‘ê»˜ ì¡°ì ˆ
        kernel = np.ones((2,2), np.uint8)
        dilated_edges = cv2.dilate(edges, kernel, iterations=1)
        
        # í° ë°°ê²½ì— ê²€ì€ ì„ 
        line_drawing = 255 - dilated_edges
        
        # ì´ë¯¸ì§€ ì €ì¥
        cv2.imwrite(save_path, line_drawing)
        print(f"âœ… [convert_bw_image] í‘ë°± ë³€í™˜ ì™„ë£Œ: {save_path}")
        
        return save_path
    
    except Exception as e:
        print(f"âŒ [convert_bw_image] ë³€í™˜ ì˜¤ë¥˜: {e}")
        return None